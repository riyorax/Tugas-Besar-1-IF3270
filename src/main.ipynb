{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF3270 Pembelajaran Mesin | Tugas Besar - Feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members:\n",
    "- Maximilian Sulistiyo (13522061)\n",
    "- Marvel Pangondian (13522075)\n",
    "- Abdullah Mubarak (13522101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we implement a custom built Feedforward Neural Network with no high-level libraries. The goal in this project is to be able to create a custom FFNN that is able to specify the type of activation function on each layer, the type of loss function, and how many neurons in each layer. We will also compare our algorithm with other built in algorithm (the sklearn MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ann import NeuralNetwork, one_hot, get_accuracy\n",
    "from dense_layer import DenseLayer\n",
    "from activations import *\n",
    "from visualizer import visualize_ann\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from activations import tanh, sigmoid, relu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy dataset and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = X.copy()\n",
    "X_original = X_original/255.0\n",
    "y_original = y.copy()\n",
    "y_original = y_original.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, train_size=60000, test_size=10000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = one_hot(y_train)\n",
    "y_test_oh = one_hot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================>] 100%\n",
      "Epoch 1/10 - 2.90s - loss: 0.0949 - accuracy: 0.4680 - val_loss: 0.0786 - val_accuracy: 0.4671\n",
      "[=================================================>] 100%\n",
      "Epoch 2/10 - 2.61s - loss: 0.0670 - accuracy: 0.6755 - val_loss: 0.0564 - val_accuracy: 0.6778\n",
      "[=================================================>] 100%\n",
      "Epoch 3/10 - 2.47s - loss: 0.0491 - accuracy: 0.7591 - val_loss: 0.0437 - val_accuracy: 0.7596\n",
      "[=================================================>] 100%\n",
      "Epoch 4/10 - 2.67s - loss: 0.0398 - accuracy: 0.8405 - val_loss: 0.0366 - val_accuracy: 0.8408\n",
      "[=================================================>] 100%\n",
      "Epoch 5/10 - 3.09s - loss: 0.0335 - accuracy: 0.8656 - val_loss: 0.0311 - val_accuracy: 0.8665\n",
      "[=================================================>] 100%\n",
      "Epoch 6/10 - 2.94s - loss: 0.0288 - accuracy: 0.8760 - val_loss: 0.0272 - val_accuracy: 0.8751\n",
      "[=================================================>] 100%\n",
      "Epoch 7/10 - 2.52s - loss: 0.0255 - accuracy: 0.8849 - val_loss: 0.0245 - val_accuracy: 0.8859\n",
      "[=================================================>] 100%\n",
      "Epoch 8/10 - 2.61s - loss: 0.0233 - accuracy: 0.8909 - val_loss: 0.0227 - val_accuracy: 0.8904\n",
      "[=================================================>] 100%\n",
      "Epoch 9/10 - 2.86s - loss: 0.0216 - accuracy: 0.8946 - val_loss: 0.0213 - val_accuracy: 0.8941\n",
      "[=================================================>] 100%\n",
      "Epoch 10/10 - 2.77s - loss: 0.0203 - accuracy: 0.8985 - val_loss: 0.0202 - val_accuracy: 0.8965\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork('mse')\n",
    "model.add_layer(DenseLayer(output_size=128, activation=relu, init=\"Xavier\"))\n",
    "model.add_layer(DenseLayer(output_size=64, activation=relu, init=\"Xavier\"))\n",
    "model.add_layer(DenseLayer(output_size=10, activation=sigmoid, init=\"Xavier\"))\n",
    "\n",
    "history = model.train(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.05,\n",
    "    isOne_hot=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8965\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "pred_classes = np.argmax(predictions, axis=1)\n",
    "accuracy = accuracy_score(pred_classes, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../ann_visualizer/output/20250327_211317_ann.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualize_ann(model,X.shape[1],output_dir='../ann_visualizer/output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of depth (Number of layers) and Width (Number of neurons per layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixed Depth\n",
    "- Number of hidden layers : 2\n",
    "- Test 1 : 64 neurons per layer\n",
    "- Test 2 : 128 neurons per layer\n",
    "- Test 3 : 256 neurons per layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================>] 100%\n",
      "Epoch 1/100 - 3.03s - loss: 0.0472 - accuracy: 0.8773 - val_loss: 0.0209 - val_accuracy: 0.8736\n",
      "[=================================================>] 100%\n",
      "Epoch 2/100 - 2.85s - loss: 0.0175 - accuracy: 0.9012 - val_loss: 0.0157 - val_accuracy: 0.8975\n",
      "[=================================================>] 100%\n",
      "Epoch 3/100 - 2.67s - loss: 0.0144 - accuracy: 0.9130 - val_loss: 0.0136 - val_accuracy: 0.9096\n",
      "[=================================================>] 100%\n",
      "Epoch 4/100 - 3.21s - loss: 0.0128 - accuracy: 0.9193 - val_loss: 0.0127 - val_accuracy: 0.9163\n",
      "[=================================================>] 100%\n",
      "Epoch 5/100 - 3.02s - loss: 0.0118 - accuracy: 0.9257 - val_loss: 0.0117 - val_accuracy: 0.9219\n",
      "[=================================================>] 100%\n",
      "Epoch 6/100 - 2.94s - loss: 0.0109 - accuracy: 0.9310 - val_loss: 0.0110 - val_accuracy: 0.9276\n",
      "[=================================================>] 100%\n",
      "Epoch 7/100 - 2.84s - loss: 0.0102 - accuracy: 0.9371 - val_loss: 0.0101 - val_accuracy: 0.9331\n",
      "[=================================================>] 100%\n",
      "Epoch 8/100 - 3.25s - loss: 0.0095 - accuracy: 0.9407 - val_loss: 0.0094 - val_accuracy: 0.9386\n",
      "[=================================================>] 100%\n",
      "Epoch 9/100 - 3.67s - loss: 0.0089 - accuracy: 0.9445 - val_loss: 0.0089 - val_accuracy: 0.9408\n",
      "[=================================================>] 100%\n",
      "Epoch 10/100 - 3.41s - loss: 0.0084 - accuracy: 0.9475 - val_loss: 0.0085 - val_accuracy: 0.9437\n",
      "[=================================================>] 100%\n",
      "Epoch 11/100 - 3.46s - loss: 0.0080 - accuracy: 0.9506 - val_loss: 0.0079 - val_accuracy: 0.9484\n",
      "[=================================================>] 100%\n",
      "Epoch 12/100 - 3.66s - loss: 0.0075 - accuracy: 0.9539 - val_loss: 0.0075 - val_accuracy: 0.9506\n",
      "[=================================================>] 100%\n",
      "Epoch 13/100 - 3.57s - loss: 0.0071 - accuracy: 0.9556 - val_loss: 0.0072 - val_accuracy: 0.9527\n",
      "[=================================================>] 100%\n",
      "Epoch 14/100 - 3.30s - loss: 0.0068 - accuracy: 0.9579 - val_loss: 0.0069 - val_accuracy: 0.9565\n",
      "[=================================================>] 100%\n",
      "Epoch 15/100 - 3.96s - loss: 0.0065 - accuracy: 0.9607 - val_loss: 0.0065 - val_accuracy: 0.9585\n",
      "[=================================================>] 100%\n",
      "Epoch 16/100 - 3.76s - loss: 0.0062 - accuracy: 0.9620 - val_loss: 0.0063 - val_accuracy: 0.9592\n",
      "[=================================================>] 100%\n",
      "Epoch 17/100 - 4.39s - loss: 0.0059 - accuracy: 0.9643 - val_loss: 0.0060 - val_accuracy: 0.9624\n",
      "[=================================================>] 100%\n",
      "Epoch 18/100 - 3.88s - loss: 0.0056 - accuracy: 0.9661 - val_loss: 0.0058 - val_accuracy: 0.9637\n",
      "[=================================================>] 100%\n",
      "Epoch 19/100 - 3.77s - loss: 0.0054 - accuracy: 0.9673 - val_loss: 0.0056 - val_accuracy: 0.9639\n",
      "[=================================================>] 100%\n",
      "Epoch 20/100 - 4.84s - loss: 0.0052 - accuracy: 0.9686 - val_loss: 0.0056 - val_accuracy: 0.9651\n",
      "[=================================================>] 100%\n",
      "Epoch 21/100 - 4.61s - loss: 0.0050 - accuracy: 0.9702 - val_loss: 0.0054 - val_accuracy: 0.9657\n",
      "[=================================================>] 100%\n",
      "Epoch 22/100 - 4.37s - loss: 0.0048 - accuracy: 0.9704 - val_loss: 0.0054 - val_accuracy: 0.9656\n",
      "[=================================================>] 100%\n",
      "Epoch 23/100 - 4.26s - loss: 0.0046 - accuracy: 0.9722 - val_loss: 0.0052 - val_accuracy: 0.9663\n",
      "[=================================================>] 100%\n",
      "Epoch 24/100 - 4.17s - loss: 0.0044 - accuracy: 0.9733 - val_loss: 0.0050 - val_accuracy: 0.9685\n",
      "[=================================================>] 100%\n",
      "Epoch 25/100 - 3.79s - loss: 0.0042 - accuracy: 0.9740 - val_loss: 0.0049 - val_accuracy: 0.9682\n",
      "[=================================================>] 100%\n",
      "Epoch 26/100 - 3.79s - loss: 0.0041 - accuracy: 0.9753 - val_loss: 0.0048 - val_accuracy: 0.9690\n",
      "[=================================================>] 100%\n",
      "Epoch 27/100 - 3.76s - loss: 0.0040 - accuracy: 0.9757 - val_loss: 0.0048 - val_accuracy: 0.9703\n",
      "[=================================================>] 100%\n",
      "Epoch 28/100 - 3.69s - loss: 0.0038 - accuracy: 0.9770 - val_loss: 0.0047 - val_accuracy: 0.9695\n",
      "[=================================================>] 100%\n",
      "Epoch 29/100 - 3.61s - loss: 0.0037 - accuracy: 0.9781 - val_loss: 0.0045 - val_accuracy: 0.9713\n",
      "[=================================================>] 100%\n",
      "Epoch 30/100 - 4.45s - loss: 0.0036 - accuracy: 0.9781 - val_loss: 0.0045 - val_accuracy: 0.9715\n",
      "[=================================================>] 100%\n",
      "Epoch 31/100 - 3.96s - loss: 0.0035 - accuracy: 0.9792 - val_loss: 0.0044 - val_accuracy: 0.9709\n",
      "[=================================================>] 100%\n",
      "Epoch 32/100 - 7.34s - loss: 0.0033 - accuracy: 0.9807 - val_loss: 0.0042 - val_accuracy: 0.9729\n",
      "[=================================================>] 100%\n",
      "Epoch 33/100 - 2.55s - loss: 0.0032 - accuracy: 0.9815 - val_loss: 0.0042 - val_accuracy: 0.9725\n",
      "[=================================================>] 100%\n",
      "Epoch 34/100 - 2.59s - loss: 0.0031 - accuracy: 0.9815 - val_loss: 0.0043 - val_accuracy: 0.9724\n",
      "[=================================================>] 100%\n",
      "Epoch 35/100 - 3.06s - loss: 0.0030 - accuracy: 0.9818 - val_loss: 0.0042 - val_accuracy: 0.9734\n",
      "[=================================================>] 100%\n",
      "Epoch 36/100 - 3.06s - loss: 0.0030 - accuracy: 0.9826 - val_loss: 0.0041 - val_accuracy: 0.9732\n",
      "[=================================================>] 100%\n",
      "Epoch 37/100 - 2.93s - loss: 0.0029 - accuracy: 0.9835 - val_loss: 0.0040 - val_accuracy: 0.9743\n",
      "[=================================================>] 100%\n",
      "Epoch 38/100 - 3.05s - loss: 0.0028 - accuracy: 0.9838 - val_loss: 0.0040 - val_accuracy: 0.9729\n",
      "[=================================================>] 100%\n",
      "Epoch 39/100 - 2.84s - loss: 0.0027 - accuracy: 0.9834 - val_loss: 0.0041 - val_accuracy: 0.9729\n",
      "[=================================================>] 100%\n",
      "Epoch 40/100 - 2.54s - loss: 0.0026 - accuracy: 0.9841 - val_loss: 0.0040 - val_accuracy: 0.9745\n",
      "[=================================================>] 100%\n",
      "Epoch 41/100 - 2.78s - loss: 0.0026 - accuracy: 0.9855 - val_loss: 0.0039 - val_accuracy: 0.9747\n",
      "[=================================================>] 100%\n",
      "Epoch 42/100 - 2.70s - loss: 0.0025 - accuracy: 0.9857 - val_loss: 0.0038 - val_accuracy: 0.9758\n",
      "[=================================================>] 100%\n",
      "Epoch 43/100 - 2.67s - loss: 0.0024 - accuracy: 0.9863 - val_loss: 0.0039 - val_accuracy: 0.9753\n",
      "[=================================================>] 100%\n",
      "Epoch 44/100 - 3.38s - loss: 0.0023 - accuracy: 0.9859 - val_loss: 0.0039 - val_accuracy: 0.9748\n",
      "[=================================================>] 100%\n",
      "Epoch 45/100 - 3.40s - loss: 0.0023 - accuracy: 0.9861 - val_loss: 0.0039 - val_accuracy: 0.9744\n",
      "[=================================================>] 100%\n",
      "Epoch 46/100 - 3.78s - loss: 0.0022 - accuracy: 0.9869 - val_loss: 0.0038 - val_accuracy: 0.9749\n",
      "[=================================================>] 100%\n",
      "Epoch 47/100 - 3.32s - loss: 0.0022 - accuracy: 0.9881 - val_loss: 0.0037 - val_accuracy: 0.9760\n",
      "[=================================================>] 100%\n",
      "Epoch 48/100 - 3.21s - loss: 0.0021 - accuracy: 0.9879 - val_loss: 0.0037 - val_accuracy: 0.9752\n",
      "[=================================================>] 100%\n",
      "Epoch 49/100 - 3.58s - loss: 0.0020 - accuracy: 0.9880 - val_loss: 0.0038 - val_accuracy: 0.9747\n",
      "[=================================================>] 100%\n",
      "Epoch 50/100 - 3.21s - loss: 0.0020 - accuracy: 0.9891 - val_loss: 0.0037 - val_accuracy: 0.9759\n",
      "[=================================================>] 100%\n",
      "Epoch 51/100 - 3.22s - loss: 0.0019 - accuracy: 0.9893 - val_loss: 0.0038 - val_accuracy: 0.9755\n",
      "[=================================================>] 100%\n",
      "Epoch 52/100 - 3.64s - loss: 0.0019 - accuracy: 0.9888 - val_loss: 0.0038 - val_accuracy: 0.9749\n",
      "[=================================================>] 100%\n",
      "Epoch 53/100 - 4.55s - loss: 0.0018 - accuracy: 0.9895 - val_loss: 0.0037 - val_accuracy: 0.9765\n",
      "[=================================================>] 100%\n",
      "Epoch 54/100 - 4.55s - loss: 0.0018 - accuracy: 0.9907 - val_loss: 0.0037 - val_accuracy: 0.9759\n",
      "[=================================================>] 100%\n",
      "Epoch 55/100 - 3.91s - loss: 0.0017 - accuracy: 0.9906 - val_loss: 0.0037 - val_accuracy: 0.9763\n",
      "[=================================================>] 100%\n",
      "Epoch 56/100 - 5.53s - loss: 0.0017 - accuracy: 0.9908 - val_loss: 0.0036 - val_accuracy: 0.9762\n",
      "[=================================================>] 100%\n",
      "Epoch 57/100 - 4.72s - loss: 0.0016 - accuracy: 0.9915 - val_loss: 0.0035 - val_accuracy: 0.9770\n",
      "[=================================================>] 100%\n",
      "Epoch 58/100 - 4.81s - loss: 0.0016 - accuracy: 0.9919 - val_loss: 0.0035 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 59/100 - 4.83s - loss: 0.0016 - accuracy: 0.9910 - val_loss: 0.0037 - val_accuracy: 0.9753\n",
      "[=================================================>] 100%\n",
      "Epoch 60/100 - 5.33s - loss: 0.0015 - accuracy: 0.9921 - val_loss: 0.0036 - val_accuracy: 0.9769\n",
      "[=================================================>] 100%\n",
      "Epoch 61/100 - 4.35s - loss: 0.0015 - accuracy: 0.9928 - val_loss: 0.0036 - val_accuracy: 0.9770\n",
      "[=================================================>] 100%\n",
      "Epoch 62/100 - 4.78s - loss: 0.0014 - accuracy: 0.9930 - val_loss: 0.0035 - val_accuracy: 0.9766\n",
      "[=================================================>] 100%\n",
      "Epoch 63/100 - 5.07s - loss: 0.0014 - accuracy: 0.9926 - val_loss: 0.0036 - val_accuracy: 0.9765\n",
      "[=================================================>] 100%\n",
      "Epoch 64/100 - 4.48s - loss: 0.0013 - accuracy: 0.9932 - val_loss: 0.0035 - val_accuracy: 0.9767\n",
      "[=================================================>] 100%\n",
      "Epoch 65/100 - 4.51s - loss: 0.0013 - accuracy: 0.9928 - val_loss: 0.0035 - val_accuracy: 0.9769\n",
      "[=================================================>] 100%\n",
      "Epoch 66/100 - 4.63s - loss: 0.0013 - accuracy: 0.9935 - val_loss: 0.0036 - val_accuracy: 0.9772\n",
      "[=================================================>] 100%\n",
      "Epoch 67/100 - 5.56s - loss: 0.0013 - accuracy: 0.9940 - val_loss: 0.0036 - val_accuracy: 0.9766\n",
      "[=================================================>] 100%\n",
      "Epoch 68/100 - 4.18s - loss: 0.0012 - accuracy: 0.9941 - val_loss: 0.0036 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 69/100 - 11.62s - loss: 0.0012 - accuracy: 0.9940 - val_loss: 0.0035 - val_accuracy: 0.9775\n",
      "[=================================================>] 100%\n",
      "Epoch 70/100 - 3.25s - loss: 0.0012 - accuracy: 0.9944 - val_loss: 0.0036 - val_accuracy: 0.9768\n",
      "[=================================================>] 100%\n",
      "Epoch 71/100 - 2.98s - loss: 0.0011 - accuracy: 0.9948 - val_loss: 0.0036 - val_accuracy: 0.9774\n",
      "[=================================================>] 100%\n",
      "Epoch 72/100 - 3.31s - loss: 0.0011 - accuracy: 0.9945 - val_loss: 0.0035 - val_accuracy: 0.9782\n",
      "[=================================================>] 100%\n",
      "Epoch 73/100 - 3.76s - loss: 0.0011 - accuracy: 0.9951 - val_loss: 0.0035 - val_accuracy: 0.9767\n",
      "[=================================================>] 100%\n",
      "Epoch 74/100 - 3.72s - loss: 0.0010 - accuracy: 0.9956 - val_loss: 0.0035 - val_accuracy: 0.9776\n",
      "[=================================================>] 100%\n",
      "Epoch 75/100 - 3.77s - loss: 0.0010 - accuracy: 0.9952 - val_loss: 0.0035 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 76/100 - 3.38s - loss: 0.0010 - accuracy: 0.9952 - val_loss: 0.0036 - val_accuracy: 0.9769\n",
      "[=================================================>] 100%\n",
      "Epoch 77/100 - 3.37s - loss: 0.0009 - accuracy: 0.9956 - val_loss: 0.0035 - val_accuracy: 0.9778\n",
      "[=================================================>] 100%\n",
      "Epoch 78/100 - 3.65s - loss: 0.0009 - accuracy: 0.9949 - val_loss: 0.0036 - val_accuracy: 0.9770\n",
      "[=================================================>] 100%\n",
      "Epoch 79/100 - 3.23s - loss: 0.0009 - accuracy: 0.9958 - val_loss: 0.0036 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 80/100 - 4.09s - loss: 0.0009 - accuracy: 0.9963 - val_loss: 0.0035 - val_accuracy: 0.9774\n",
      "[=================================================>] 100%\n",
      "Epoch 81/100 - 3.96s - loss: 0.0008 - accuracy: 0.9966 - val_loss: 0.0035 - val_accuracy: 0.9772\n",
      "[=================================================>] 100%\n",
      "Epoch 82/100 - 4.15s - loss: 0.0008 - accuracy: 0.9965 - val_loss: 0.0035 - val_accuracy: 0.9770\n",
      "[=================================================>] 100%\n",
      "Epoch 83/100 - 3.91s - loss: 0.0008 - accuracy: 0.9966 - val_loss: 0.0035 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 84/100 - 4.32s - loss: 0.0008 - accuracy: 0.9965 - val_loss: 0.0035 - val_accuracy: 0.9776\n",
      "[=================================================>] 100%\n",
      "Epoch 85/100 - 4.52s - loss: 0.0007 - accuracy: 0.9970 - val_loss: 0.0035 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 86/100 - 4.37s - loss: 0.0007 - accuracy: 0.9967 - val_loss: 0.0036 - val_accuracy: 0.9768\n",
      "[=================================================>] 100%\n",
      "Epoch 87/100 - 3.59s - loss: 0.0007 - accuracy: 0.9968 - val_loss: 0.0036 - val_accuracy: 0.9767\n",
      "[=================================================>] 100%\n",
      "Epoch 88/100 - 4.07s - loss: 0.0007 - accuracy: 0.9973 - val_loss: 0.0035 - val_accuracy: 0.9774\n",
      "[=================================================>] 100%\n",
      "Epoch 89/100 - 3.74s - loss: 0.0007 - accuracy: 0.9969 - val_loss: 0.0037 - val_accuracy: 0.9770\n",
      "[=================================================>] 100%\n",
      "Epoch 90/100 - 4.12s - loss: 0.0007 - accuracy: 0.9976 - val_loss: 0.0036 - val_accuracy: 0.9769\n",
      "[=================================================>] 100%\n",
      "Epoch 91/100 - 4.72s - loss: 0.0006 - accuracy: 0.9977 - val_loss: 0.0035 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 92/100 - 4.38s - loss: 0.0006 - accuracy: 0.9978 - val_loss: 0.0035 - val_accuracy: 0.9780\n",
      "[=================================================>] 100%\n",
      "Epoch 93/100 - 3.69s - loss: 0.0006 - accuracy: 0.9979 - val_loss: 0.0035 - val_accuracy: 0.9766\n",
      "[=================================================>] 100%\n",
      "Epoch 94/100 - 8.13s - loss: 0.0006 - accuracy: 0.9980 - val_loss: 0.0035 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 95/100 - 5.18s - loss: 0.0006 - accuracy: 0.9980 - val_loss: 0.0035 - val_accuracy: 0.9774\n",
      "[=================================================>] 100%\n",
      "Epoch 96/100 - 4.37s - loss: 0.0005 - accuracy: 0.9980 - val_loss: 0.0036 - val_accuracy: 0.9769\n",
      "[=================================================>] 100%\n",
      "Epoch 97/100 - 5.20s - loss: 0.0005 - accuracy: 0.9982 - val_loss: 0.0036 - val_accuracy: 0.9771\n",
      "[=================================================>] 100%\n",
      "Epoch 98/100 - 4.85s - loss: 0.0005 - accuracy: 0.9983 - val_loss: 0.0036 - val_accuracy: 0.9772\n",
      "[=================================================>] 100%\n",
      "Epoch 99/100 - 7.37s - loss: 0.0005 - accuracy: 0.9983 - val_loss: 0.0035 - val_accuracy: 0.9773\n",
      "[=================================================>] 100%\n",
      "Epoch 100/100 - 5.38s - loss: 0.0005 - accuracy: 0.9984 - val_loss: 0.0035 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.047184172174571756,\n",
       "  0.017456997277249607,\n",
       "  0.014354399284281071,\n",
       "  0.012842256548322497,\n",
       "  0.011802394439441116,\n",
       "  0.010922624635694801,\n",
       "  0.01021323554874847,\n",
       "  0.009500601850681878,\n",
       "  0.008932191202756103,\n",
       "  0.008422398925574831,\n",
       "  0.007966618253229701,\n",
       "  0.007531403731605003,\n",
       "  0.007131747127303836,\n",
       "  0.006779255397957534,\n",
       "  0.006453089799938571,\n",
       "  0.006158278321156281,\n",
       "  0.005874351344794269,\n",
       "  0.005640456968780611,\n",
       "  0.005376614479449596,\n",
       "  0.005155199235909341,\n",
       "  0.0049508553737461075,\n",
       "  0.004758971208682892,\n",
       "  0.004573907879507656,\n",
       "  0.004399023950075666,\n",
       "  0.004247971977211571,\n",
       "  0.004101145480680023,\n",
       "  0.0039535427460946695,\n",
       "  0.0038246552226254248,\n",
       "  0.0036837433150429763,\n",
       "  0.0035661973609378756,\n",
       "  0.0034541174423023072,\n",
       "  0.0033403453897131075,\n",
       "  0.0032415226922945196,\n",
       "  0.0031384275627202095,\n",
       "  0.003035432398565227,\n",
       "  0.002965290002988181,\n",
       "  0.0028777677930909417,\n",
       "  0.002775267099861831,\n",
       "  0.002717364499977342,\n",
       "  0.0026303523966053457,\n",
       "  0.0025664861454394775,\n",
       "  0.0024914675347521803,\n",
       "  0.0024043356832939805,\n",
       "  0.0023459254575571914,\n",
       "  0.002283610792742859,\n",
       "  0.0022125472097250113,\n",
       "  0.0021515876339244034,\n",
       "  0.0021031902505931313,\n",
       "  0.0020324423796867935,\n",
       "  0.0019826070410314265,\n",
       "  0.0019307079602317251,\n",
       "  0.0018847647588006269,\n",
       "  0.001824881202039878,\n",
       "  0.0017786483563621632,\n",
       "  0.0017198248237090775,\n",
       "  0.0016843447329888427,\n",
       "  0.0016352694809005238,\n",
       "  0.001589544763904879,\n",
       "  0.001556055889189572,\n",
       "  0.0015079180061263809,\n",
       "  0.001464330235060235,\n",
       "  0.0014256387625050187,\n",
       "  0.0013831744681113913,\n",
       "  0.0013499405489611695,\n",
       "  0.0013171504315325651,\n",
       "  0.0012844955281280884,\n",
       "  0.0012506128816229516,\n",
       "  0.0012140281250698202,\n",
       "  0.0011911091871681318,\n",
       "  0.0011522609532184519,\n",
       "  0.001125151033336199,\n",
       "  0.0010849907294584417,\n",
       "  0.0010548616539060674,\n",
       "  0.0010325875353697986,\n",
       "  0.0009947454080861786,\n",
       "  0.0009795422729635913,\n",
       "  0.000931008749727634,\n",
       "  0.0009158138678897542,\n",
       "  0.0008953254779128229,\n",
       "  0.0008633811679189323,\n",
       "  0.0008486564852657174,\n",
       "  0.0008160087386522683,\n",
       "  0.0007939403024278726,\n",
       "  0.0007717321301182272,\n",
       "  0.0007441952419750108,\n",
       "  0.0007247613211536051,\n",
       "  0.0007073612131176187,\n",
       "  0.0006884593832792638,\n",
       "  0.0006741149039197182,\n",
       "  0.0006517710751088158,\n",
       "  0.0006364667589343707,\n",
       "  0.0006093004486944398,\n",
       "  0.0005936918617597104,\n",
       "  0.0005761612964936765,\n",
       "  0.0005587519371816444,\n",
       "  0.000547284305125774,\n",
       "  0.000528242239710772,\n",
       "  0.0005114498154990461,\n",
       "  0.0004974509318225613,\n",
       "  0.0004771202414410728],\n",
       " 'val_loss': [array(0.02088509),\n",
       "  array(0.01565451),\n",
       "  array(0.01361592),\n",
       "  array(0.01265925),\n",
       "  array(0.01172592),\n",
       "  array(0.01095371),\n",
       "  array(0.01009285),\n",
       "  array(0.00935261),\n",
       "  array(0.0088926),\n",
       "  array(0.00846587),\n",
       "  array(0.00785023),\n",
       "  array(0.00753228),\n",
       "  array(0.00717552),\n",
       "  array(0.00690698),\n",
       "  array(0.00645412),\n",
       "  array(0.00633462),\n",
       "  array(0.00599471),\n",
       "  array(0.00576137),\n",
       "  array(0.00562464),\n",
       "  array(0.00555969),\n",
       "  array(0.00543433),\n",
       "  array(0.00535772),\n",
       "  array(0.0051735),\n",
       "  array(0.00497964),\n",
       "  array(0.00493358),\n",
       "  array(0.00478761),\n",
       "  array(0.00475688),\n",
       "  array(0.00465954),\n",
       "  array(0.00448665),\n",
       "  array(0.00448887),\n",
       "  array(0.00443422),\n",
       "  array(0.00424522),\n",
       "  array(0.00419485),\n",
       "  array(0.00427031),\n",
       "  array(0.00416353),\n",
       "  array(0.00409227),\n",
       "  array(0.00396813),\n",
       "  array(0.00403162),\n",
       "  array(0.00410648),\n",
       "  array(0.00402184),\n",
       "  array(0.00388202),\n",
       "  array(0.00382331),\n",
       "  array(0.00385873),\n",
       "  array(0.00389683),\n",
       "  array(0.00386844),\n",
       "  array(0.00379642),\n",
       "  array(0.00369743),\n",
       "  array(0.00372704),\n",
       "  array(0.00382782),\n",
       "  array(0.00367837),\n",
       "  array(0.00377096),\n",
       "  array(0.0038074),\n",
       "  array(0.00368791),\n",
       "  array(0.0036661),\n",
       "  array(0.00366639),\n",
       "  array(0.00361391),\n",
       "  array(0.00354021),\n",
       "  array(0.00354399),\n",
       "  array(0.00373145),\n",
       "  array(0.00358972),\n",
       "  array(0.00356269),\n",
       "  array(0.00350425),\n",
       "  array(0.00360245),\n",
       "  array(0.00353327),\n",
       "  array(0.00354826),\n",
       "  array(0.00360056),\n",
       "  array(0.00357558),\n",
       "  array(0.00355855),\n",
       "  array(0.00353588),\n",
       "  array(0.00359207),\n",
       "  array(0.00356253),\n",
       "  array(0.0035198),\n",
       "  array(0.00354692),\n",
       "  array(0.00349384),\n",
       "  array(0.00353223),\n",
       "  array(0.00358727),\n",
       "  array(0.00346916),\n",
       "  array(0.00361554),\n",
       "  array(0.00355735),\n",
       "  array(0.0034916),\n",
       "  array(0.00350996),\n",
       "  array(0.00351683),\n",
       "  array(0.00353412),\n",
       "  array(0.00354426),\n",
       "  array(0.00352568),\n",
       "  array(0.00358733),\n",
       "  array(0.00356136),\n",
       "  array(0.00350982),\n",
       "  array(0.00366416),\n",
       "  array(0.00359846),\n",
       "  array(0.00354665),\n",
       "  array(0.00354517),\n",
       "  array(0.00354576),\n",
       "  array(0.00348356),\n",
       "  array(0.00354784),\n",
       "  array(0.0035729),\n",
       "  array(0.00356822),\n",
       "  array(0.00356807),\n",
       "  array(0.00351468),\n",
       "  array(0.00349696)],\n",
       " 'accuracy': [0.87735,\n",
       "  0.9012166666666667,\n",
       "  0.9130166666666667,\n",
       "  0.9193166666666667,\n",
       "  0.9256666666666666,\n",
       "  0.9310333333333334,\n",
       "  0.9370833333333334,\n",
       "  0.9406833333333333,\n",
       "  0.9444666666666667,\n",
       "  0.9474666666666667,\n",
       "  0.9505666666666667,\n",
       "  0.9539,\n",
       "  0.9556,\n",
       "  0.9578666666666666,\n",
       "  0.9607166666666667,\n",
       "  0.962,\n",
       "  0.9643333333333334,\n",
       "  0.9661166666666666,\n",
       "  0.9673166666666667,\n",
       "  0.96855,\n",
       "  0.9701666666666666,\n",
       "  0.9703666666666667,\n",
       "  0.97225,\n",
       "  0.9732666666666666,\n",
       "  0.974,\n",
       "  0.9753,\n",
       "  0.9757333333333333,\n",
       "  0.977,\n",
       "  0.97815,\n",
       "  0.9780833333333333,\n",
       "  0.9792166666666666,\n",
       "  0.9807333333333333,\n",
       "  0.9814666666666667,\n",
       "  0.9815333333333334,\n",
       "  0.9818166666666667,\n",
       "  0.9826,\n",
       "  0.9835166666666667,\n",
       "  0.98375,\n",
       "  0.9834,\n",
       "  0.9840833333333333,\n",
       "  0.98545,\n",
       "  0.98565,\n",
       "  0.9862833333333333,\n",
       "  0.9859,\n",
       "  0.9861,\n",
       "  0.9869333333333333,\n",
       "  0.98815,\n",
       "  0.98795,\n",
       "  0.98805,\n",
       "  0.9890833333333333,\n",
       "  0.9893166666666666,\n",
       "  0.9888,\n",
       "  0.9895,\n",
       "  0.9907,\n",
       "  0.9905833333333334,\n",
       "  0.9908,\n",
       "  0.9915166666666667,\n",
       "  0.9919166666666667,\n",
       "  0.991,\n",
       "  0.99215,\n",
       "  0.99275,\n",
       "  0.9929833333333333,\n",
       "  0.9925666666666667,\n",
       "  0.99325,\n",
       "  0.9927666666666667,\n",
       "  0.9934833333333334,\n",
       "  0.9939833333333333,\n",
       "  0.9941333333333333,\n",
       "  0.99405,\n",
       "  0.9943666666666666,\n",
       "  0.9948166666666667,\n",
       "  0.9945333333333334,\n",
       "  0.9951,\n",
       "  0.99555,\n",
       "  0.9952,\n",
       "  0.9952,\n",
       "  0.9955666666666667,\n",
       "  0.9949333333333333,\n",
       "  0.9957666666666667,\n",
       "  0.9962833333333333,\n",
       "  0.9966333333333334,\n",
       "  0.9965333333333334,\n",
       "  0.99655,\n",
       "  0.9964833333333334,\n",
       "  0.9970166666666667,\n",
       "  0.9967333333333334,\n",
       "  0.9967666666666667,\n",
       "  0.99735,\n",
       "  0.9969,\n",
       "  0.9976333333333334,\n",
       "  0.99765,\n",
       "  0.9978333333333333,\n",
       "  0.9978666666666667,\n",
       "  0.9979833333333333,\n",
       "  0.998,\n",
       "  0.99805,\n",
       "  0.9982333333333333,\n",
       "  0.9983,\n",
       "  0.9983,\n",
       "  0.9984333333333333],\n",
       " 'val_accuracy': [0.8736,\n",
       "  0.8975,\n",
       "  0.9096,\n",
       "  0.9163,\n",
       "  0.9219,\n",
       "  0.9276,\n",
       "  0.9331,\n",
       "  0.9386,\n",
       "  0.9408,\n",
       "  0.9437,\n",
       "  0.9484,\n",
       "  0.9506,\n",
       "  0.9527,\n",
       "  0.9565,\n",
       "  0.9585,\n",
       "  0.9592,\n",
       "  0.9624,\n",
       "  0.9637,\n",
       "  0.9639,\n",
       "  0.9651,\n",
       "  0.9657,\n",
       "  0.9656,\n",
       "  0.9663,\n",
       "  0.9685,\n",
       "  0.9682,\n",
       "  0.969,\n",
       "  0.9703,\n",
       "  0.9695,\n",
       "  0.9713,\n",
       "  0.9715,\n",
       "  0.9709,\n",
       "  0.9729,\n",
       "  0.9725,\n",
       "  0.9724,\n",
       "  0.9734,\n",
       "  0.9732,\n",
       "  0.9743,\n",
       "  0.9729,\n",
       "  0.9729,\n",
       "  0.9745,\n",
       "  0.9747,\n",
       "  0.9758,\n",
       "  0.9753,\n",
       "  0.9748,\n",
       "  0.9744,\n",
       "  0.9749,\n",
       "  0.976,\n",
       "  0.9752,\n",
       "  0.9747,\n",
       "  0.9759,\n",
       "  0.9755,\n",
       "  0.9749,\n",
       "  0.9765,\n",
       "  0.9759,\n",
       "  0.9763,\n",
       "  0.9762,\n",
       "  0.977,\n",
       "  0.9771,\n",
       "  0.9753,\n",
       "  0.9769,\n",
       "  0.977,\n",
       "  0.9766,\n",
       "  0.9765,\n",
       "  0.9767,\n",
       "  0.9769,\n",
       "  0.9772,\n",
       "  0.9766,\n",
       "  0.9771,\n",
       "  0.9775,\n",
       "  0.9768,\n",
       "  0.9774,\n",
       "  0.9782,\n",
       "  0.9767,\n",
       "  0.9776,\n",
       "  0.9771,\n",
       "  0.9769,\n",
       "  0.9778,\n",
       "  0.977,\n",
       "  0.9771,\n",
       "  0.9774,\n",
       "  0.9772,\n",
       "  0.977,\n",
       "  0.9771,\n",
       "  0.9776,\n",
       "  0.9771,\n",
       "  0.9768,\n",
       "  0.9767,\n",
       "  0.9774,\n",
       "  0.977,\n",
       "  0.9769,\n",
       "  0.9771,\n",
       "  0.978,\n",
       "  0.9766,\n",
       "  0.9771,\n",
       "  0.9774,\n",
       "  0.9769,\n",
       "  0.9771,\n",
       "  0.9772,\n",
       "  0.9773,\n",
       "  0.9767]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test_1_fixed_depth = NeuralNetwork('mse')\n",
    "model_test_1_fixed_depth.add_layer(DenseLayer(output_size=128, activation=relu, init=\"Xavier\"))\n",
    "model_test_1_fixed_depth.add_layer(DenseLayer(output_size=64, activation=relu, init=\"Xavier\"))\n",
    "model_test_1_fixed_depth.add_layer(DenseLayer(output_size=10, activation=softmax, init=\"Xavier\"))\n",
    "\n",
    "model_test_1_fixed_depth.train(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.05,\n",
    "    isOne_hot=True,\n",
    "    verbose=1,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_test_1_fixed_depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions_test_1_fixed_depth \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_test_1_fixed_depth\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m pred_classes_test_1_fixed_depth \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions_test_1_fixed_depth, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m accuracy_test_1_fixed_depth \u001b[38;5;241m=\u001b[39m accuracy_score(pred_classes_test_1_fixed_depth, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_test_1_fixed_depth' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_test_1_fixed_depth = model_test_1_fixed_depth.predict(X_test)\n",
    "pred_classes_test_1_fixed_depth = np.argmax(predictions_test_1_fixed_depth, axis=1)\n",
    "accuracy_test_1_fixed_depth = accuracy_score(pred_classes_test_1_fixed_depth, y_test)\n",
    "print(\"Test Accuracy:\", accuracy_test_1_fixed_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_visualizer/output\\interactive_neural_network.html\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ann_visualizer/output\\\\interactive_neural_network.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m### Visualizer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mvisualize_ann\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_test_1_fixed_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\StudyMain\\KULIAH\\Semester 6\\Temp\\src\\visualizer.py:116\u001b[0m, in \u001b[0;36mvisualize_ann\u001b[1;34m(model, input_shape, filename, auto_open)\u001b[0m\n\u001b[0;32m    109\u001b[0m network_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m'\u001b[39m: nodes,\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m'\u001b[39m: edges\n\u001b[0;32m    112\u001b[0m }\n\u001b[0;32m    114\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m html_path \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_html_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../static/style.css\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../static/script.js\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m html_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m html_path\n",
      "File \u001b[1;32md:\\StudyMain\\KULIAH\\Semester 6\\Temp\\src\\visualizer.py:153\u001b[0m, in \u001b[0;36mcreate_html_file\u001b[1;34m(network_data, loss_fn, filename, css_path, js_path)\u001b[0m\n\u001b[0;32m    151\u001b[0m html_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mann_visualizer/output\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(html_path)\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhtml_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    154\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(html)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m html_path\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ann_visualizer/output\\\\interactive_neural_network.html'"
     ]
    }
   ],
   "source": [
    "### Visualizer\n",
    "visualize_ann(model_test_1_fixed_depth,X.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model with sklearn MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.37724840\n",
      "Iteration 2, loss = 0.15004672\n",
      "Iteration 3, loss = 0.10562821\n",
      "Iteration 4, loss = 0.08064147\n",
      "Iteration 5, loss = 0.06428497\n",
      "Iteration 6, loss = 0.05121985\n",
      "Iteration 7, loss = 0.04219482\n",
      "Iteration 8, loss = 0.03723277\n",
      "Iteration 9, loss = 0.02986735\n",
      "Iteration 10, loss = 0.02325205\n",
      "Iteration 11, loss = 0.02124234\n",
      "Iteration 12, loss = 0.01549812\n",
      "Iteration 13, loss = 0.01433403\n",
      "Iteration 14, loss = 0.01377085\n",
      "Iteration 15, loss = 0.00927998\n",
      "Iteration 16, loss = 0.00973711\n",
      "Iteration 17, loss = 0.01097088\n",
      "Iteration 18, loss = 0.00895768\n",
      "Iteration 19, loss = 0.00620646\n",
      "Iteration 20, loss = 0.00376964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=20, random_state=1,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=20, random_state=1,\n",
       "              verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=20, random_state=1,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(128, 64),activation='relu', \n",
    "                    solver='adam', max_iter=20, random_state=1, verbose=True)\n",
    "\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier Test Accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp = mlp.predict(X_test)\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(f\"MLPClassifier Test Accuracy: {acc_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       986\n",
      "           1       0.99      0.99      0.99      1125\n",
      "           2       0.97      0.98      0.98       999\n",
      "           3       0.99      0.95      0.97      1020\n",
      "           4       0.98      0.98      0.98       975\n",
      "           5       0.96      0.98      0.97       902\n",
      "           6       0.99      0.99      0.99       982\n",
      "           7       0.98      0.98      0.98      1042\n",
      "           8       0.98      0.97      0.97       975\n",
      "           9       0.95      0.99      0.97       994\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_mlp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
